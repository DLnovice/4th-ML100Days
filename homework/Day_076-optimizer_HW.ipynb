{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業重點:\n",
    "\n",
    "(1)以, Adam, 為例, 調整 batch_size, epoch , 觀察accurancy, loss 的變化\n",
    "\n",
    "(2)以同一模型, 分別驗證 SGD, Adam, Rmsprop 的 accurancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業目標:\n",
    "    \n",
    "    取得各種優化器的運算結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "#from keras.datasets import cifar10\n",
    "from keras.datasets import mnist \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_loss_plotter(history_dict, title):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))\n",
    "    \n",
    "    acc_values = history_dict['accuracy']\n",
    "    val_acc_values = history_dict['val_acc']\n",
    "    loss_values = history_dict['loss']\n",
    "    val_loss_values = history_dict['val_loss']\n",
    "    epochs = range(1, len(acc_values) + 1)\n",
    "    \n",
    "    ax1.plot(epochs, acc_values, 'k:', label='training accuracy')\n",
    "    ax1.plot(epochs, val_acc_values, 'b--', label='validation accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.set_title(title)\n",
    "\n",
    "    ax2.plot(epochs, loss_values, 'k:', label='training loss')\n",
    "    ax2.plot(epochs, val_loss_values, 'b--', label='validation loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_set():\n",
    "    # 第一步：選擇模型, 順序模型是多個網絡層的線性堆疊\n",
    "    model = Sequential()\n",
    "\n",
    "    # 第二步：構建網絡層\n",
    "    model.add(Dense(32,input_shape=(784,))) # 輸入層，28*28=784   \n",
    "    model.add(Activation('relu')) # 激活函數是relu   \n",
    "\n",
    "    model.add(Dense(32)) # 隱藏層節點32個   \n",
    "    model.add(Activation('relu'))  \n",
    "\n",
    "    model.add(Dense(32)) # 隱藏層節點32個   \n",
    "    model.add(Activation('relu'))  \n",
    "\n",
    "    model.add(Dense(32)) # 隱藏層節點32個   \n",
    "    model.add(Activation('relu'))  \n",
    "\n",
    "    model.add(Dense(10)) # 輸出結果是10個類別，所以維度是10   \n",
    "    model.add(Activation('softmax')) # 最後一層用softmax作為激活函數\n",
    "    # 模型建立完成後，統計參數總量\n",
    "    print(\"Total Parameters：%d\" % model.count_params())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第四步：資料分割\n",
    "# 使用Keras自帶的mnist工具讀取數據（第一次需要聯網）\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
    "\n",
    "# 由於mist的輸入數據維度是(num, 28 , 28)，這裡需要把後面的維度直接拼起來變成784維   \n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])  \n",
    "Y_train = (numpy.arange(10) == y_train[:, None]).astype(int)\n",
    "Y_test = (numpy.arange(10) == y_test[:, None]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters：28618\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-55fa3ab8c2bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=0, \n\u001b[0;32m     15\u001b[0m                             validation_split=0.3)\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0macc_loss_plotter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-0a712c6b2c8d>\u001b[0m in \u001b[0;36macc_loss_plotter\u001b[1;34m(history_dict, title)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0macc_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mval_acc_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mloss_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mval_loss_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_acc'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 第三步：編譯\n",
    "'''\n",
    "   宣告並設定\n",
    "   batch_size：對總的樣本數進行分組，每組包含的樣本數量\n",
    "   epochs：訓練次數\n",
    "   \n",
    "''' \n",
    "for batch_size in [128, 256]:\n",
    "    for epochs in [20, 30]:\n",
    "        optimizer = 'Adam'\n",
    "        title = f'optimizer = {optimizer}, batch_size = {batch_size}, epochs = {epochs}'\n",
    "        model = model_set()\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=0, \n",
    "                            validation_split=0.3)\n",
    "        acc_loss_plotter(history.history, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for optimizer in ['Adam', 'SGD', 'Rmsprop']:\n",
    "    batch_size, epochs = 128, 20  \n",
    "    title = f'optimizer = {optimizer}, batch_size = {batch_size}, epochs = {epochs}'\n",
    "    model = model_set()\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=0, \n",
    "                        validation_split=0.3)\n",
    "    acc_loss_plotter(history.history, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "   第五步：訓練\n",
    "   .fit的一些參數\n",
    "   batch_size：對總的樣本數進行分組，每組包含的樣本數量\n",
    "   epochs ：訓練次數\n",
    "   shuffle：是否把數據隨機打亂之後再進行訓練\n",
    "   validation_split：拿出百分之多少用來做交叉驗證\n",
    "   verbose：屏顯模式 - 0：不輸出, 1：輸出進度, 2：輸出每次的訓練結果\n",
    "''' \n",
    "\n",
    "#Blas GEMM launch failed , 避免動態分配GPU / CPU, 出現問題\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "model = model_set()\n",
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=8, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第三步：編譯\n",
    "'''\n",
    "   宣告並設定\n",
    "   batch_size：對總的樣本數進行分組，每組包含的樣本數量\n",
    "   epochs：訓練次數\n",
    "   \n",
    "''' \n",
    "for batch_size in [128, 256]:\n",
    "    for epochs in [20, 30]:\n",
    "        optimizer = 'Adam'\n",
    "        title = f'optimizer = {optimizer}, batch_size = {batch_size}, epochs = {epochs}'\n",
    "        model = model_set()\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, shuffle=True, verbose=0, \n",
    "                            validation_split=0.3)\n",
    "        acc_loss_plotter(history.history, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第六步：輸出\n",
    "evaluation = model.evaluate(X_test, Y_test)\n",
    "print(f\"loss = {evaluation[0]:.3f}, accuracy={evaluation[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
